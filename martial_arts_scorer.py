import streamlit as st
import cv2
import mediapipe as mp
import numpy as np
from scipy.spatial.distance import euclidean
from dtw import dtw 
import tempfile
import time
import os

# Kh·ªüi t·∫°o MediaPipe Pose
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

# H·∫±ng s·ªë v√† C·∫•u h√¨nh
DEFAULT_SCORE = 100
# H·ªá s·ªë ƒëi·ªÅu ch·ªânh.
SCORE_SCALING_FACTOR = 10.0 
MIN_BODY_PARTS_FOR_CHECK = 10 # S·ªë l∆∞·ª£ng kh·ªõp t·ªëi thi·ªÉu c·∫ßn c√≥ ƒë·ªÉ so s√°nh

# ƒê·ªãnh nghƒ©a m·ª©c ƒëi·ªÉm t·ªëi ƒëa cho t·ª´ng nh√≥m ti√™u ch√≠ (T·ªïng = 100)
MAX_SCORE_KT = 40 # K·ªπ thu·∫≠t 
MAX_SCORE_BD = 40 # Bi·ªÉu di·ªÖn
MAX_SCORE_TT = 20 # Trang ph·ª•c/Th·∫ßn th√°i
PENALTY_PER_MISTAKE = 1.0 # Tr·ª´ 1 ƒëi·ªÉm cho m·ªói l·ªói n·∫∑ng (simulated)

st.set_page_config(layout="centered", page_title="H·ªá Th·ªëng Ch·∫•m ƒêi·ªÉm B√†i V√µ AI")

def normalize_pose_data(landmarks):
    """
    Chu·∫©n h√≥a d·ªØ li·ªáu t·ªça ƒë·ªô kh·ªõp (landmarks) ƒë·ªÉ lo·∫°i b·ªè y·∫øu t·ªë v·ªã tr√≠ v√† k√≠ch th∆∞·ªõc.
    1. Chu·∫©n h√≥a v·ªã tr√≠ (ƒë·∫∑t kh·ªõp h√¥ng/gi·ªØa c∆° th·ªÉ v·ªÅ (0,0)).
    2. Chu·∫©n h√≥a k√≠ch th∆∞·ªõc (chia cho chi·ªÅu d√†i th√¢n ng∆∞·ªùi).
    """
    if not landmarks:
        return None

    # L·∫•y t·ªça ƒë·ªô kh·ªõp h√¥ng (v√≠ d·ª•: LEFT_HIP, RIGHT_HIP) ƒë·ªÉ l√†m t√¢m
    try:
        left_hip = np.array([landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,
                             landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y])
        right_hip = np.array([landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,
                              landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y])
        
        # T√¢m c∆° th·ªÉ l√† ƒëi·ªÉm gi·ªØa hai h√¥ng
        center = (left_hip + right_hip) / 2
        
        # Chi·ªÅu d√†i c∆° th·ªÉ (v√≠ d·ª•: kho·∫£ng c√°ch gi·ªØa vai v√† h√¥ng) ƒë·ªÉ chu·∫©n h√≥a k√≠ch th∆∞·ªõc
        left_shoulder = np.array([landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                                  landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y])
        
        # S·ª≠ d·ª•ng kho·∫£ng c√°ch vai-h√¥ng l√†m y·∫øu t·ªë t·ª∑ l·ªá (scale factor)
        scale_factor = euclidean(left_hip, left_shoulder) * 2 
        
        if scale_factor < 1e-6: # Tr√°nh chia cho 0
            scale_factor = 1.0
            
    except Exception:
        # N·∫øu kh√¥ng ƒë·ªß kh·ªõp h√¥ng/vai, kh√¥ng th·ªÉ chu·∫©n h√≥a
        return None

    normalized_data = []
    # Tr√≠ch xu·∫•t 33 kh·ªõp, m·ªói kh·ªõp 2 t·ªça ƒë·ªô (x, y) = 66 gi√° tr·ªã
    for landmark in landmarks:
        # Chu·∫©n h√≥a: (t·ªça ƒë·ªô - t√¢m) / y·∫øu t·ªë t·ª∑ l·ªá
        normalized_x = (landmark.x - center[0]) / scale_factor
        normalized_y = (landmark.y - center[1]) / scale_factor
        
        normalized_data.append(normalized_x)
        normalized_data.append(normalized_y)
        
    return np.array(normalized_data)


# ƒê√£ lo·∫°i b·ªè @st.cache_data ƒë·ªÉ thanh ti·∫øn tr√¨nh ho·∫°t ƒë·ªông theo th·ªùi gian th·ª±c
def process_video(uploaded_file, name, progress_placeholder, progress_start, progress_end):
    """
    X·ª≠ l√Ω video, tr√≠ch xu·∫•t t·ªça ƒë·ªô kh·ªõp v√† chu·∫©n h√≥a, c√≥ c·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh.
    """
    all_normalized_poses = []
    temp_file_path = None

    try:
        # L∆∞u file ƒë√£ upload v√†o th∆∞ m·ª•c t·∫°m th·ªùi
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{name}.mp4") as tfile: 
            tfile.write(uploaded_file.read())
            temp_file_path = tfile.name
        
        cap = cv2.VideoCapture(temp_file_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total_frames == 0:
            raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c video ho·∫∑c video tr·ªëng.")
        
        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
            frame_count = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Chuy·ªÉn ƒë·ªïi sang RGB v√† x·ª≠ l√Ω
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                image.flags.writeable = False
                results = pose.process(image)
                image.flags.writeable = True

                # Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a d·ªØ li·ªáu t∆∞ th·∫ø
                if results.pose_landmarks:
                    landmarks = results.pose_landmarks.landmark
                    normalized_pose = normalize_pose_data(landmarks)
                    
                    # Ch·ªâ l∆∞u n·∫øu chu·∫©n h√≥a th√†nh c√¥ng v√† c√≥ ƒë·ªß s·ªë l∆∞·ª£ng kh·ªõp
                    if normalized_pose is not None and len(normalized_pose) >= MIN_BODY_PARTS_FOR_CHECK * 2:
                        all_normalized_poses.append(normalized_pose)

                frame_count += 1
                
                # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh: 
                # (Ph·∫ßn trƒÉm ban ƒë·∫ßu) + (Ph·∫°m vi x·ª≠ l√Ω) * (T·ª∑ l·ªá khung h√¨nh ƒë√£ x·ª≠ l√Ω)
                current_progress = progress_start + (progress_end - progress_start) * (frame_count / total_frames)
                progress_placeholder.progress(int(current_progress))


    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω video {name}: {e}")
        return np.array([])
    finally:
        # ƒê·∫£m b·∫£o gi·∫£i ph√≥ng cap v√† x√≥a file t·∫°m
        if 'cap' in locals():
            cap.release()
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)

    if not all_normalized_poses:
        st.error(f"Kh√¥ng th·ªÉ ph√°t hi·ªán ƒë·ªß t∆∞ th·∫ø trong video {name}. Vui l√≤ng ki·ªÉm tra ch·∫•t l∆∞·ª£ng video.")
        return np.array([])
        
    return np.array(all_normalized_poses)

def calculate_score(std_poses, student_poses):
    """
    So s√°nh hai chu·ªói t∆∞ th·∫ø ƒë√£ chu·∫©n h√≥a v√† t√≠nh ƒëi·ªÉm b·∫±ng Dynamic Time Warping (DTW).
    """
    
    len_std = std_poses.shape[0]
    len_student = student_poses.shape[0]

    if len_std == 0 or len_student == 0:
        return 0.0, 0.0
    
    try:
        # 1. Th·ª±c hi·ªán DTW
        alignment = dtw(std_poses, student_poses, dist_method=euclidean)

        # 2. L·∫•y Sai L·ªách DTW v√† Chu·∫©n h√≥a th·ªß c√¥ng (Manual Normalization)
        total_dtw_distance = alignment.distance
        
        # Chu·∫©n h√≥a b·∫±ng c√°ch chia cho ƒë·ªô d√†i c·ªßa chu·ªói chu·∫©n
        avg_dtw_error = total_dtw_distance / len_std
        
    except Exception as e:
        # G·ª° b·ªè th√¥ng b√°o l·ªói trong qu√° tr√¨nh ch·∫°y, ch·ªâ gi·ªØ l·∫°i th√¥ng b√°o l·ªói l·ªõn
        raise Exception(f"L·ªói DTW: {e}")


    # 3. Chuy·ªÉn ƒë·ªïi Sai L·ªách th√†nh ƒêi·ªÉm
    raw_score = DEFAULT_SCORE - (avg_dtw_error * SCORE_SCALING_FACTOR)
    final_score = np.clip(raw_score, 0, DEFAULT_SCORE)

    return final_score, avg_dtw_error

def generate_breakdown_table(final_score, avg_dtw_error):
    """
    T·∫°o b·∫£ng ph√¢n t√≠ch chi ti·∫øt ƒëi·ªÉm s·ªë d·ª±a tr√™n t·ªïng ƒëi·ªÉm cu·ªëi c√πng v√† sai l·ªách DTW.
    Ph√¢n b·ªï ƒëi·ªÉm sai l·ªách theo t·ª∑ l·ªá ƒë√£ ƒë·ªãnh (KT: 40%, BD: 40%, TT: 20%).
    """
    
    # S·ªë ƒëi·ªÉm b·ªã tr·ª´ so v·ªõi ƒëi·ªÉm tuy·ªát ƒë·ªëi 100
    total_deduction = DEFAULT_SCORE - final_score
    
    # --- M√¥ ph·ªèng tr·ª´ ƒëi·ªÉm theo t·ª´ng nh√≥m ti√™u ch√≠ (KT, BD, TT) ---
    
    # 1. K·ªπ thu·∫≠t (KT): Chi·∫øm 40% ƒëi·ªÉm tr·ª´
    deduction_kt = total_deduction * 0.4
    score_kt = np.clip(MAX_SCORE_KT - deduction_kt, 0, MAX_SCORE_KT)
    
    # 2. Bi·ªÉu di·ªÖn (BD): Chi·∫øm 40% ƒëi·ªÉm tr·ª´
    deduction_bd = total_deduction * 0.4
    score_bd = np.clip(MAX_SCORE_BD - deduction_bd, 0, MAX_SCORE_BD)

    # 3. Trang ph·ª•c/Th·∫ßn th√°i (TT): Chi·∫øm 20% ƒëi·ªÉm tr·ª´ (Gi·∫£ ƒë·ªãnh)
    deduction_tt = total_deduction * 0.2
    score_tt = np.clip(MAX_SCORE_TT - deduction_tt, 0, MAX_SCORE_TT)

    # T·ªïng ƒëi·ªÉm m√¥ ph·ªèng (Ph·∫£i b·∫±ng Final Score)
    simulated_total_score = score_kt + score_bd + score_tt
    
    # --- Chu·∫©n b·ªã d·ªØ li·ªáu cho b·∫£ng ---
    data = [
        ("K·ªπ thu·∫≠t (KT)", MAX_SCORE_KT, f"{score_kt:.2f}", f"B·ªã tr·ª´: {deduction_kt:.2f}"),
        ("Bi·ªÉu di·ªÖn (BD)", MAX_SCORE_BD, f"{score_bd:.2f}", f"B·ªã tr·ª´: {deduction_bd:.2f}"),
        ("Trang ph·ª•c/Th·∫ßn th√°i (TT)", MAX_SCORE_TT, f"{score_tt:.2f}", f"B·ªã tr·ª´: {deduction_tt:.2f}"),
        ("T·ªîNG C·ªòNG", DEFAULT_SCORE, f"{simulated_total_score:.2f}", f"T·ªïng sai l·ªách: {total_deduction:.2f}")
    ]

    # --- T·∫°o b·∫£ng Markdown ---
    table = "| Ti√™u ch√≠ | Max ƒêi·ªÉm | ƒêi·ªÉm ƒê·∫°t ƒê∆∞·ª£c | Ghi ch√∫ (M√¥ ph·ªèng) |\n"
    table += "| :--- | :---: | :---: | :--- |\n"
    for row in data:
        table += f"| **{row[0]}** | **{row[1]}** | **{row[2]}** | {row[3]} |\n"
        
    # Th√™m chi ti·∫øt c√°c ti√™u ch√≠ con (Ch·ªâ l√† m√¥ t·∫£, kh√¥ng t√≠nh ƒëi·ªÉm ri√™ng)
    details = f"""
    ### üìù Chi ti·∫øt Ti√™u ch√≠ (M·ª©c ƒëi·ªÉm ƒë√£ ƒë∆∞·ª£c ph√¢n b·ªï)
    | Ti√™u ch√≠ | M√¥ t·∫£ | 
    | :--- | :--- |
    | **KT1-KT4** | Chu·∫©n x√°c t·∫•n ph√°p, th·ªß ph√°p, c∆∞·ªõc ph√°p; thƒÉng b·∫±ng v√† k·ªπ ph√°p kh√≥. |
    | **BD1-BD5** | S·ª©c m·∫°nh, s·ª©c b·ªÅn, bi√™n ƒë·ªô, ti·∫øt t·∫•u v√† ƒëi·ªÉm d·ª´ng k·ªπ thu·∫≠t. |
    | **TT1-TT4** | Trang ph·ª•c, bi·ªÉu c·∫£m, th·∫ßn th√°i, nh√£n ph√°p, ti·∫øng h√°t/ph√°t l·ª±c. |
    """
    
    # Th√™m ph·∫ßn tr·ª´ ƒëi·ªÉm n·∫∑ng (simulated)
    penalty_placeholder = f"""
    ### ‚ö†Ô∏è C√°c tr∆∞·ªùng h·ª£p B·ªã Tr·ª´ ƒêi·ªÉm Nghi√™m Tr·ªçng
    *L∆∞u √Ω: ·ª®ng d·ª•ng AI hi·ªán t·∫°i kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c c√°c l·ªói sau, nh∆∞ng m√¥ ph·ªèng tr·ª´ **{PENALTY_PER_MISTAKE} ƒëi·ªÉm** m·ªói l·ªói.*
    1. B·ªã tr∆∞·ª£t ng√£ / Kh√¥ng thu·ªôc b√†i / R∆°i binh kh√≠. (Gi·∫£ ƒë·ªãnh V√µ sinh m·∫Øc **0** l·ªói).
    """

    return table, details, penalty_placeholder


# --- Giao Di·ªán Streamlit ---
st.markdown("""
    <style>
    .big-font {
        font-size:30px !important;
        font-weight: bold;
        color: #007bff;
        text-align: center;
        margin-bottom: 20px;
    }
    .main-score {
        font-size: 72px !important;
        font-weight: 900;
        color: #28a745;
        text-align: center;
        padding: 20px;
        border: 4px solid #28a745;
        border-radius: 15px;
        margin-top: 30px;
    }
    .stFileUploader {
        margin-bottom: 20px;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown('<p class="big-font">ü•ã H·ªá Th·ªëng Ch·∫•m ƒêi·ªÉm B√†i V√µ AI ü•ã</p>', unsafe_allow_html=True)

# Khai b√°o Placeholder cho k·∫øt qu·∫£ v√† ti·∫øn tr√¨nh (M·ª•c ti√™u: ƒê∆∞a k·∫øt qu·∫£ l√™n ƒë·∫ßu)
result_container = st.container()
progress_container = st.container()

st.write("Vui l√≤ng t·∫£i l√™n video chu·∫©n (Ki·ªán T∆∞·ªõng) v√† video c·ªßa V√µ Sinh ƒë·ªÉ so s√°nh t∆∞ th·∫ø v√† ch·∫•m ƒëi·ªÉm.")

col1, col2 = st.columns(2)

with col1:
    standard_video_file = st.file_uploader(
        "T·∫£i l√™n Video Chu·∫©n (Ki·ªán T∆∞·ªõng)",
        type=['mp4', 'mov', 'avi'],
        key="standard_upload"
    )

with col2:
    student_video_file = st.file_uploader(
        "T·∫£i l√™n Video V√µ Sinh",
        type=['mp4', 'mov', 'avi'],
        key="student_upload"
    )

st.markdown("---")

if standard_video_file and student_video_file:
    
    if st.button("üöÄ B·∫Øt ƒê·∫ßu So S√°nh Ch·∫•m ƒêi·ªÉm"):
        
        # Thi·∫øt l·∫≠p khu v·ª±c hi·ªÉn th·ªã ti·∫øn tr√¨nh
        progress_bar = progress_container.progress(0)
        status_text = progress_container.empty()
        
        status_text.info("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
        
        # 1. Tr√≠ch xu·∫•t T∆∞ th·∫ø (Pose Estimation)
        try:
            start_time = time.time()
            
            # X·ª≠ l√Ω Video Chu·∫©n (0% -> 50%)
            status_text.info("ƒêang x·ª≠ l√Ω Video Chu·∫©n (1/2)...")
            std_poses = process_video(standard_video_file, "Video Chu·∫©n", progress_bar, 0, 50)
            
            # X·ª≠ l√Ω Video V√µ Sinh (50% -> 100%)
            status_text.info("ƒêang x·ª≠ l√Ω Video V√µ Sinh (2/2)...")
            student_poses = process_video(student_video_file, "Video V√µ Sinh", progress_bar, 50, 95)
            
            progress_bar.progress(98)
            status_text.info("Ho√†n th√†nh tr√≠ch xu·∫•t. B·∫Øt ƒë·∫ßu t√≠nh to√°n DTW...")


            if std_poses.shape[0] == 0 or student_poses.shape[0] == 0:
                result_container.error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu t∆∞ th·∫ø ƒë·ªÉ so s√°nh. Vui l√≤ng ki·ªÉm tra l·∫°i ch·∫•t l∆∞·ª£ng video.")
            else:
                # 2. T√≠nh to√°n ƒêi·ªÉm s·ªë
                final_score, avg_error = calculate_score(std_poses, student_poses)
                
                # 3. T·∫°o b·∫£ng ph√¢n t√≠ch k·∫øt qu·∫£
                breakdown_table, details_markdown, penalty_markdown = generate_breakdown_table(final_score, avg_error)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£ (S·ª≠ d·ª•ng result_container ƒë·ªÉ ƒë∆∞a l√™n tr√™n)
                with result_container:
                    st.balloons()
                    st.markdown(f"""
                        <div class="main-score">
                            {final_score:.2f} / 100
                        </div>
                    """, unsafe_allow_html=True)
                    
                    st.success(f"‚úÖ So s√°nh ho√†n th√†nh! Video V√µ Sinh ƒë·∫°t **{final_score:.2f} / 100 ƒëi·ªÉm** so v·ªõi video Chu·∫©n.")
                    
                    # Hi·ªÉn th·ªã b·∫£ng chi ti·∫øt
                    st.markdown("---")
                    st.markdown("## üìä B·∫£ng Th·ªëng K√™ K·∫øt Qu·∫£ Chi Ti·∫øt")
                    st.markdown(breakdown_table)
                    st.markdown(details_markdown)
                    st.markdown(penalty_markdown)

                    st.markdown("---")
                    st.markdown("### üîç Ph√¢n t√≠ch K·ªπ thu·∫≠t N·ªÅn t·∫£ng")
                    st.write(f"- Ph∆∞∆°ng ph√°p so s√°nh: **Dynamic Time Warping (DTW)**")
                    st.write(f"- Sai l·ªách DTW ƒë√£ Chu·∫©n h√≥a theo ƒë·ªô d√†i chu·∫©n (Standard Length Normalized DTW Error): **{avg_error:.4f}**")
                    st.write(f"- T·ªïng th·ªùi gian x·ª≠ l√Ω: **{time.time() - start_time:.2f} gi√¢y**.")

        except Exception as e:
            result_container.error(f"ƒê√£ x·∫£y ra l·ªói nghi√™m tr·ªçng: {e}")
            result_container.warning("Xin l∆∞u √Ω: ·ª®ng d·ª•ng n√†y y√™u c·∫ßu hi·ªáu nƒÉng x·ª≠ l√Ω cao, n·∫øu video qu√° d√†i ho·∫∑c ch·∫•t l∆∞·ª£ng th·∫•p c√≥ th·ªÉ g√¢y l·ªói.")

        # Ho√†n th√†nh 100% v√† ·∫©n thanh ti·∫øn tr√¨nh
        progress_bar.progress(100)
        status_text.empty()
        time.sleep(1)
        progress_container.empty() # X√≥a khu v·ª±c ti·∫øn tr√¨nh

elif standard_video_file or student_video_file:
    st.warning("Vui l√≤ng t·∫£i l√™n c·∫£ hai video (Chu·∫©n v√† V√µ Sinh) ƒë·ªÉ b·∫Øt ƒë·∫ßu so s√°nh.")
else:
    st.info("Ch·ªù t·∫£i l√™n 2 video...")
